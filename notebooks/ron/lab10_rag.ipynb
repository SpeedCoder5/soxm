{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrival-Augmented Generation (RAG) Example\n",
    "\n",
    "This notebook demonstrates how to use Retrieval-Augmented Generation (RAG) to improve responses using the OpenAI API.\n",
    "\n",
    "First, copy this lab to your notebooks folder.\n",
    "\n",
    "## Step 1: Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "print(f'Using openai {openai.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Set Up API Key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values()\n",
    "openai_api_key = config['OPENAI_API_KEY']\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "# Define a function to get a response from OpenAI API\n",
    "def get_openai_response(client, input_text, model):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": input_text,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: Create a List of Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of facts\n",
    "facts = [\n",
    "    \"The Eiffel Tower is in Paris.\",\n",
    "    \"The Great Wall of China can be seen from space.\",\n",
    "    \"The largest mammal is the blue whale.\",\n",
    "    \"Venus is the hottest planet in our solar system.\",\n",
    "    \"Honey never spoils.\"\n",
    "]\n",
    "facts_words = [fact.lower().strip('.').split(' ') for fact in facts]\n",
    "facts_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 4: Define a Simple Retrieval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve relevant facts\n",
    "# This very simple toy example returns a list of facts that have any relavant word from query.\n",
    "# In the real world you would use search with links to a document store.\n",
    "def retrieve_facts(query, facts):\n",
    "    facts_words = [fact.lower().strip('.').split(' ') for fact in facts]\n",
    "    exclude = ['a','the','of','is']\n",
    "    query_words = [word for word in query.lower().strip('.').split(' ') if word not in exclude]\n",
    "    relevant_facts = {} # dict keys only allow unique key values\n",
    "    for query_word in query_words:\n",
    "        for fact, fact_words in zip(facts, facts_words):\n",
    "            for query_word in query_words:\n",
    "                if query_word in fact_words:\n",
    "                    relevant_facts[fact] = '' \n",
    "                    break\n",
    "    return list(relevant_facts.keys())\n",
    "\n",
    "# Test the function\n",
    "retrieve_facts(\"the hottest tower\", facts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 5: Use the Retrieved Facts to Generate a Response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example query\n",
    "query = \"Tell me about the Eiffel Tower and space.\"\n",
    "\n",
    "# Retrieve relevant facts\n",
    "relevant_facts = retrieve_facts(query, facts)\n",
    "relevant_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine relevant facts\n",
    "context = \" \".join(relevant_facts)\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=f\"{context} Based on these facts, {query}\"\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a response using the OpenAI API\n",
    "model =\"gpt-3.5-turbo\"\n",
    "response = get_openai_response(client, prompt, model)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document what you learned in Overleaf.\n",
    "\n",
    "Will you use RAG any part of your project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soxm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
